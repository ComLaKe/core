\chapter{Introduction}
\section{Motivation}
Many researchers at \gls{usth} operate with data on a regular basis
and often a dataset is studied by multiple researchers from different
departments and points in time.  Currently the data are organized manually,
even on the laboratories' storages, which is prone to duplication
and makes data discovery difficult.

A data lake shared among the university's researchers, professors and students
will not only save resources but also improve productivity and promote
interdisciplinary collaborations.  With \gls{usth}'s goal of growing to be
an excellent research university in {\selectlanguage{vietnamese}Viá»‡t Nam}
and in the region~\cite{usth}, building such data lake can be an essential task.

\section{Background}
A \emph{data lake} is a massive repository of multiple types of data
in their raw format at scale for a low cost~\cite{lake}.
The data's schema (structure) is defined on read to minimize data modeling
and integration costs~\cite{lake}.

For the ease and efficiency of scaling, a microservice architecture
could be a good choice.  By arranging the data lake as a collection
of loosely-coupled services, it becomes possible to scale individual services
individually~\cite{micro}.  In this architecture, the \emph{core} microservice
is defined as the innermost component, which communicates directly
with the storages.  The core shall provide an \gls{api} for other components
to upload, query and extract data.

\emph{Append-only storages} only allow new data to be appended, whilst ensure
the immutability of existing data.  As immutable data are thread-safe,
they reduce the complexity of the concurrency model, making it easier
to comprehend and reason about~\cite{pure}.  This is particularly useful
in large distributed systems with multiple moving parts.

Since the data are immutable, each \emph{\gls{content}} can be given
an \gls{id}, i.e.~a \gls{cid}.  For end-users, we also introduce
a higher level concept: \emph{dataset}, composing of not only the content
but also relevant metadata for indexing.  Like contents, datasets can also
immutable, with changes written as a new revision linking to the previous one.

Append-only storages' operations boil down to two kinds: appending and reading.
For the latter, sometimes the data are not wanted in their entirety,
but filtered and accumulated.  While data of different types usually requires
different tools and libraries to query upon, the core \gls{api} should be
providing one single query language for all data types, plus their metadata.
In this thesis, such usage is referred to as \emph{query polymorphism}.

\section{Objectives}
The work presented here was done as part of a three-month internship
in collaboration with several other students
at \gls{usth} ICTLab\footnote{\url{https://ictlab.usth.edu.vn}} to build
a data lake for a better management of the university's data.  The internship
focused on the lake's core microservice, which abstracts underlying
persistent layers and perform relevant metadata transformation and discovery.
It should provide an internal interface to other components for data ingestion,
(primitive) query and extraction, as well as carrying out tasks for enhancing
the discoverability and usability of the aforementioned datasets.

After the internship period, the resulting codebase shall be maintained
by ICTLab and future students, so the work must be designed, implemented
and documented in a way that ensures such possibility.

\section{Expected Outcomes}
The intended deliverables of the three-month internship are listed as follows:
\begin{itemize}
  \item Requirement analysis of the data lake core
  \item Data lake core's architecture and design
  \item Core \gls{api} design and specification
  \item Implementation and integration with other components
\end{itemize}
